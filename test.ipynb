{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataloaders\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "from ops.utils_blocks import block_module\n",
    "from ops.utils import  str2bool\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from globals import args\n",
    "args.test_path = \"./datasets/testing\";\n",
    "args.testidx = 1;\n",
    "args.noise_level = 0;\n",
    "args.model_name = \"gray.ckpt\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data : ['./datasets/testing']\n",
      "loading spams dict @ ./datasets/dictionnaries/256_9x9.pt\n",
      "Arguments: {'mode': 'group', 'stride': 1, 'num_filters': 256, 'kernel_size': 9, 'noise_level': 0, 'unfoldings': 24, 'patch_size': 56, 'rescaling_init_val': 1.0, 'lmbda_prox': 0.02, 'spams_init': 1, 'nu_init': 1, 'corr_update': 3, 'multi_theta': 1, 'diag_rescale_gamma': 0, 'diag_rescale_patch': 1, 'freq_corr_update': 6, 'mask_windows': 1, 'center_windows': 1, 'multi_std': 0, 'lr': 0.0006, 'lr_step': 80, 'lr_decay': 0.35, 'backtrack_decay': 0.8, 'eps': 0.001, 'validation_every': 10, 'backtrack': 1, 'num_epochs': 300, 'train_batch': 25, 'aug_scale': 0, 'test_batch': 10, 'model_name': 'gray.ckpt', 'data_path': './datasets/', 'stride_test': 12, 'stride_val': 48, 'test_every': 100, 'pad_image': 0, 'pad_block': 1, 'pad_patch': 0, 'no_pad': False, 'custom_pad': None, 'testpath': './datasets/testing', 'testidx': 1, 'verbose': 0, 'nu_var': 0.01, 'freq_var': 3, 'var_reg': False, 'fff': '/home/hristina/.local/share/jupyter/runtime/kernel-e65d904a-57fc-42d1-92b1-c71423743007.json', 'test_path': './datasets/testing'}\n",
      "Nb tensors:  29 ; Trainable Params:  68434 ; device:  cpu ; name :  cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'cpu'\n",
    "capability = torch.cuda.get_device_capability(0) if torch.cuda.is_available() else os.cpu_count()\n",
    "\n",
    "test_path = [args.testpath]\n",
    "print(f'test data : {test_path}')\n",
    "train_path = val_path = []\n",
    "\n",
    "noise_std = args.noise_level / 255\n",
    "\n",
    "loaders = dataloaders.get_dataloaders(train_path, test_path, train_path, crop_size=args.patch_size,\n",
    "    batch_size=args.train_batch, downscale=args.aug_scale, concat=1,grey=True)\n",
    "\n",
    "from model import ListaParams\n",
    "from model import groupLista as Lista\n",
    "\n",
    "params = ListaParams(kernel_size=args.kernel_size, num_filters=args.num_filters, stride=args.stride,\n",
    "    unfoldings=args.unfoldings, freq=args.freq_corr_update, corr_update=args.corr_update,\n",
    "    lmbda_init=args.lmbda_prox, h=args.rescaling_init_val, spams=args.spams_init,\n",
    "    multi_lmbda=args.multi_theta,\n",
    "    center_windows=args.center_windows, std_gamma=args.diag_rescale_gamma,\n",
    "    std_y=args.diag_rescale_patch, block_size=args.patch_size, nu_init=args.nu_init,\n",
    "    mask=args.mask_windows, multi_std=args.multi_std, freq_var=args.freq_var, var_reg=args.var_reg,nu_var=args.nu_var)\n",
    "\n",
    "model = Lista(params).to(device=device)\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Arguments: {vars(args)}')\n",
    "print('Nb tensors: ',len(list(model.named_parameters())), \"; Trainable Params: \", pytorch_total_params, \"; device: \", device,\n",
    "      \"; name : \", device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " existing ckpt detected\n",
      "=> loaded checkpoint 'gray.ckpt' (epoch 300)\n",
      "\n",
      "starting eval on test set with stride 12...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "groupLista(\n",
       "  (apply_A): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (apply_D): Conv2d(256, 81, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (apply_W): Conv2d(256, 81, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (simLayer): ModuleList(\n",
       "    (0): SoftMatchingLayer()\n",
       "  )\n",
       "  (std): ParameterList(  (0): Parameter containing: [torch.float32 of size 1x81x1x1])\n",
       "  (nu): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])\n",
       "  (lmbda): ParameterList(\n",
       "      (0): Parameter containing: [torch.float32 of size 1x256x1x1]\n",
       "      (1): Parameter containing: [torch.float32 of size 1x256x1x1]\n",
       "      (2): Parameter containing: [torch.float32 of size 1x256x1x1]\n",
       "      (3): Parameter containing: [torch.float32 of size 1x256x1x1]\n",
       "      (4): Parameter containing: [torch.float32 of size 1x256x1x1]\n",
       "      (5): Parameter containing: [torch.float32 of size 1x256x1x1]\n",
       "      (6): Parameter containing: [torch.float32 of size 1x256x1x1]\n",
       "      (7): Parameter containing: [torch.float32 of size 1x256x1x1]\n",
       "      (8): Parameter containing: [torch.float32 of size 1x256x1x1]\n",
       "      (9): Parameter containing: [torch.float32 of size 1x256x1x1]\n",
       "      (10): Parameter containing: [torch.float32 of size 1x256x1x1]\n",
       "      (11): Parameter containing: [torch.float32 of size 1x256x1x1]\n",
       "      (12): Parameter containing: [torch.float32 of size 1x256x1x1]\n",
       "      (13): Parameter containing: [torch.float32 of size 1x256x1x1]\n",
       "      (14): Parameter containing: [torch.float32 of size 1x256x1x1]\n",
       "      (15): Parameter containing: [torch.float32 of size 1x256x1x1]\n",
       "      (16): Parameter containing: [torch.float32 of size 1x256x1x1]\n",
       "      (17): Parameter containing: [torch.float32 of size 1x256x1x1]\n",
       "      (18): Parameter containing: [torch.float32 of size 1x256x1x1]\n",
       "      (19): Parameter containing: [torch.float32 of size 1x256x1x1]\n",
       "      (20): Parameter containing: [torch.float32 of size 1x256x1x1]\n",
       "      (21): Parameter containing: [torch.float32 of size 1x256x1x1]\n",
       "      (22): Parameter containing: [torch.float32 of size 1x256x1x1]\n",
       "      (23): Parameter containing: [torch.float32 of size 1x256x1x1]\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = args.model_name\n",
    "out_dir = os.path.join(model_name)\n",
    "ckpt_path = os.path.join(out_dir)\n",
    "config_dict = vars(args)\n",
    "\n",
    "if os.path.isfile(ckpt_path):\n",
    "    try:\n",
    "        print('\\n existing ckpt detected')\n",
    "        checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        psnr_validation = checkpoint['psnr_validation']\n",
    "        model.load_state_dict(checkpoint['state_dict'],strict=True)\n",
    "        print(f\"=> loaded checkpoint '{ckpt_path}' (epoch {start_epoch})\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f'ckpt loading failed @{ckpt_path}, exit ...')\n",
    "        exit()\n",
    "\n",
    "l = args.kernel_size // 2\n",
    "tic = time.time()\n",
    "phase = 'test'\n",
    "print(f'\\nstarting eval on test set with stride {args.stride_test}...')\n",
    "model.eval()  # Set model to evaluate mode, we don't want to calculate gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE LOADED:  0 ./datasets/testing/Test-01.png\n",
      "IMAGE LOADED:  1 ./datasets/testing/Test-02.jpeg\n"
     ]
    }
   ],
   "source": [
    "num_iters = 0\n",
    "psnr_tot = 0\n",
    "stride_test = args.stride_test\n",
    "\n",
    "loader = loaders['test']\n",
    "batch = list(loader)[args.testidx]\n",
    "batch = batch.to(device=device)\n",
    "\n",
    "noise = torch.randn_like(batch) * noise_std\n",
    "noisy_batch = batch + noise\n",
    "\n",
    "f, axs = plt.subplots(1, 2, constrained_layout=True);\n",
    "axs[0].imshow(batch[0,0], cmap='gray');\n",
    "axs[0].set_title(\"Original Image\");\n",
    "axs[1].imshow(noisy_batch[0,0], cmap='gray');\n",
    "axs[1].set_title(\"Noised Image\");\n",
    "axs[0].axis('off');\n",
    "axs[1].axis('off');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable pytorch gradient calculations (we're in test mode)\n",
    "with torch.set_grad_enabled(False):\n",
    "    params = {\n",
    "        'crop_out_blocks': 0,\n",
    "        'ponderate_out_blocks': 1,\n",
    "        'sum_blocks': 0,\n",
    "        'pad_even': 1,  # otherwise pad with 0 for las\n",
    "        'centered_pad': 0,  # corner pixel have only one estimate\n",
    "        'pad_block': args.pad_block,  # pad so each pixel has S**2 estimate\n",
    "        'pad_patch': args.pad_patch,  # pad so each pixel from the image has at least S**2 estimate from 1 block\n",
    "        'no_pad': args.no_pad,\n",
    "        'custom_pad': args.custom_pad,\n",
    "        'avg': 1}\n",
    "\n",
    "    # Split input image into N separate patch, with some stride\n",
    "    block = block_module(args.patch_size, stride_test, args.kernel_size, params)\n",
    "    batch_noisy_blocks = block._make_blocks(noisy_batch)\n",
    "    patch_loader = torch.utils.data.DataLoader(batch_noisy_blocks, batch_size=args.test_batch, drop_last=False)\n",
    "\n",
    "    # Run each patch through the neural network to denoise it\n",
    "    batch_out_blocks = torch.zeros_like(batch_noisy_blocks)\n",
    "    for i, inp in enumerate(tqdm(patch_loader)):  # if it doesnt fit in memory\n",
    "        id_from, id_to = i * patch_loader.batch_size, (i + 1) * patch_loader.batch_size\n",
    "        batch_out_blocks[id_from:id_to] = model(inp)\n",
    "\n",
    "    # Take a mean of our blocks, recombine them into our output image\n",
    "    output = block._agregate_blocks(batch_out_blocks)\n",
    "    \n",
    "    f, axs = plt.subplots(1, 3, constrained_layout=True);\n",
    "    axs[0].imshow(batch[0,0], cmap='gray');\n",
    "    axs[0].set_title(\"Original Image\");\n",
    "    axs[1].imshow(noisy_batch[0,0], cmap='gray');\n",
    "    axs[1].set_title(\"Noised Image\");\n",
    "    axs[2].imshow(output[0,0], cmap='gray');\n",
    "    axs[2].set_title(\"Output Image\");\n",
    "    axs[0].axis('off');\n",
    "    axs[1].axis('off');\n",
    "    axs[2].axis('off');\n",
    "    plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "1dc0eb9d0d92d45e45eca7a6ed58e808c5c22521bcd639a1dc66acf689965710"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
