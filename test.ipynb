{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.16 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/nix/store/83sfdiij18jf9qqz11vva6xilvhggi0k-python3-3.8.16-env/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import dataloaders\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import argparses\n",
    "import os\n",
    "import time\n",
    "from ops.utils_blocks import block_module\n",
    "from ops.utils import  str2bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.16 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/nix/store/83sfdiij18jf9qqz11vva6xilvhggi0k-python3-3.8.16-env/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from globals import args\n",
    "args.test_path = \"./datasets/testing\";\n",
    "args.testidx = 1;\n",
    "args.noise_level = 0;\n",
    "args.model_name = \"gray.ckpt\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'cpu'\n",
    "capability = torch.cuda.get_device_capability(0) if torch.cuda.is_available() else os.cpu_count()\n",
    "\n",
    "test_path = [args.testpath]\n",
    "print(f'test data : {test_path}')\n",
    "train_path = val_path = []\n",
    "\n",
    "noise_std = args.noise_level / 255\n",
    "\n",
    "loaders = dataloaders.get_dataloaders(train_path, test_path, train_path, crop_size=args.patch_size,\n",
    "    batch_size=args.train_batch, downscale=args.aug_scale, concat=1,grey=True)\n",
    "\n",
    "from model import ListaParams\n",
    "from model import groupLista as Lista\n",
    "\n",
    "params = ListaParams(kernel_size=args.kernel_size, num_filters=args.num_filters, stride=args.stride,\n",
    "    unfoldings=args.unfoldings, freq=args.freq_corr_update, corr_update=args.corr_update,\n",
    "    lmbda_init=args.lmbda_prox, h=args.rescaling_init_val, spams=args.spams_init,\n",
    "    multi_lmbda=args.multi_theta,\n",
    "    center_windows=args.center_windows, std_gamma=args.diag_rescale_gamma,\n",
    "    std_y=args.diag_rescale_patch, block_size=args.patch_size, nu_init=args.nu_init,\n",
    "    mask=args.mask_windows, multi_std=args.multi_std, freq_var=args.freq_var, var_reg=args.var_reg,nu_var=args.nu_var)\n",
    "\n",
    "model = Lista(params).to(device=device)\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Arguments: {vars(args)}')\n",
    "print('Nb tensors: ',len(list(model.named_parameters())), \"; Trainable Params: \", pytorch_total_params, \"; device: \", device,\n",
    "      \"; name : \", device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = args.model_name\n",
    "out_dir = os.path.join(model_name)\n",
    "ckpt_path = os.path.join(out_dir)\n",
    "config_dict = vars(args)\n",
    "\n",
    "if os.path.isfile(ckpt_path):\n",
    "    try:\n",
    "        print('\\n existing ckpt detected')\n",
    "        checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        psnr_validation = checkpoint['psnr_validation']\n",
    "        model.load_state_dict(checkpoint['state_dict'],strict=True)\n",
    "        print(f\"=> loaded checkpoint '{ckpt_path}' (epoch {start_epoch})\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f'ckpt loading failed @{ckpt_path}, exit ...')\n",
    "        exit()\n",
    "\n",
    "l = args.kernel_size // 2\n",
    "tic = time.time()\n",
    "phase = 'test'\n",
    "print(f'\\nstarting eval on test set with stride {args.stride_test}...')\n",
    "model.eval()  # Set model to evaluate mode, we don't want to calculate gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iters = 0\n",
    "psnr_tot = 0\n",
    "stride_test = args.stride_test\n",
    "\n",
    "loader = loaders['test']\n",
    "batch = list(loader)[args.testidx]\n",
    "batch = batch.to(device=device)\n",
    "\n",
    "noise = torch.randn_like(batch) * noise_std\n",
    "noisy_batch = batch + noise\n",
    "\n",
    "f, axs = plt.subplots(1, 2, constrained_layout=True);\n",
    "axs[0].imshow(batch[0,0], cmap='gray');\n",
    "axs[0].set_title(\"Original Image\");\n",
    "axs[1].imshow(noisy_batch[0,0], cmap='gray');\n",
    "axs[1].set_title(\"Noised Image\");\n",
    "axs[0].axis('off');\n",
    "axs[1].axis('off');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable pytorch gradient calculations (we're in test mode)\n",
    "with torch.set_grad_enabled(False):\n",
    "    params = {\n",
    "        'crop_out_blocks': 0,\n",
    "        'ponderate_out_blocks': 1,\n",
    "        'sum_blocks': 0,\n",
    "        'pad_even': 1,  # otherwise pad with 0 for las\n",
    "        'centered_pad': 0,  # corner pixel have only one estimate\n",
    "        'pad_block': args.pad_block,  # pad so each pixel has S**2 estimate\n",
    "        'pad_patch': args.pad_patch,  # pad so each pixel from the image has at least S**2 estimate from 1 block\n",
    "        'no_pad': args.no_pad,\n",
    "        'custom_pad': args.custom_pad,\n",
    "        'avg': 1}\n",
    "\n",
    "    # Split input image into N separate patch, with some stride\n",
    "    block = block_module(args.patch_size, stride_test, args.kernel_size, params)\n",
    "    batch_noisy_blocks = block._make_blocks(noisy_batch)\n",
    "    patch_loader = torch.utils.data.DataLoader(batch_noisy_blocks, batch_size=args.test_batch, drop_last=False)\n",
    "\n",
    "    # Run each patch through the neural network to denoise it\n",
    "    batch_out_blocks = torch.zeros_like(batch_noisy_blocks)\n",
    "    for i, inp in enumerate(tqdm(patch_loader)):  # if it doesnt fit in memory\n",
    "        id_from, id_to = i * patch_loader.batch_size, (i + 1) * patch_loader.batch_size\n",
    "        batch_out_blocks[id_from:id_to] = model(inp)\n",
    "\n",
    "    # Take a mean of our blocks, recombine them into our output image\n",
    "    output = block._agregate_blocks(batch_out_blocks)\n",
    "    \n",
    "    f, axs = plt.subplots(1, 3, constrained_layout=True);\n",
    "    axs[0].imshow(batch[0,0], cmap='gray');\n",
    "    axs[0].set_title(\"Original Image\");\n",
    "    axs[1].imshow(noisy_batch[0,0], cmap='gray');\n",
    "    axs[1].set_title(\"Noised Image\");\n",
    "    axs[2].imshow(output[0,0], cmap='gray');\n",
    "    axs[2].set_title(\"Output Image\");\n",
    "    axs[0].axis('off');\n",
    "    axs[1].axis('off');\n",
    "    axs[2].axis('off');\n",
    "    plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1dc0eb9d0d92d45e45eca7a6ed58e808c5c22521bcd639a1dc66acf689965710"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
